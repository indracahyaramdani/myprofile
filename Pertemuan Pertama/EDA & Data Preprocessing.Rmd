---
title: "EDA & Data Preprocessing in R"
author: "Indra Cahya Ramdani"
date: "3/17/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

![](https://drive.google.com/uc?id=1-CkViCEe_aRWGzvLqCu15w3VMXbDQfsF)

## **Pendahuluan**

### Import Library
```{r}
if(!require(tidyverse)) install.packages("tidyverse")
if(!require(skimr)) install.packages("skimr")
if(!require(DataExplorer)) install.packages("DataExplorer")
if(!require(visdat)) install.packages("visdat")
if(!require(heatmaply)) install.packages("heatmaply")
if(!require(psych)) install.packages("psych")

library(heatmaply) #Untuk plot heatmap Missing Data
library(visdat)
library(tidyverse)
library(skimr)
library(DataExplorer)
library(dplyr)
library(ggplot2)
library(tidyr)
library(readr)
library(tibble)
library(reshape2) #Modifikasi DataFrame
library(psych) #Pair Plot
```
### Mengakses Dataset

```{r}
df<- read.csv("https://raw.githubusercontent.com/indracahyaramdani/PSDS-Kelas-Mahir/main/Pertemuan%20Pertama/titanic_modify.csv",stringsAsFactors = T)
df[df == ""] <- NA
df[0:10,]

head(df)
```

### Tujuan Analisis Data
Melakukan klasifikasi penumpang yang selamat dan tidak selamat pada kasus tenggelamnya kapal Titanic.

### Memahami dataset

Dataset Titanic dibuat untuk membuat machine learning untuk melakukan klasifikasi biner(Selamat atau Tidak Selamat. Variabel-variabel yang terdapat pada dataset ini adalah sebagai berikut:

1. **PassengerId** = Nomor Id Penumpang 
2. **Survived** = Keterangan Selamat(0=Tidak, 1=Ya)
3. **Pclass** = Kelas Tiket (1=Kelas 1, 2=Kelas 2, dst)
4. **Name** = Nama Penumpang
5. **Sex** = Jenis kelamin
6. **Age** = Usia dalam tahun
7. **SibSp** = Jumlah saudara kandung / pasangan di kapal Titanic
8. **Parch** = Jumlah orang tua / anak di kapal Titanic
9. **Ticket** = Nomor Tiket
10. **Fare** = Harga Tiket
11. **Cabin** = Nama Kabin
12. **Embarked** = Pelabuhan Asal (C = Cherbourg, Q = Queenstown, S = Southampton)

## **Eksploratory Data Analysis**

### Dimensi Data
```{r}
dim(df)
```
Artinya kita memiliki data dengan 12 kolom dan 707 baris

### Variabel Pada Dataset

```{r}
names(df)
```
Terdapat 12 Feature yaitu {"PassengerId", "Survived", "Pclass", "Name", "Sex", "Age", "SibSp","Parch","Ticket","Fare","Cabin","Embarked" }
```{r}
str(df)
```
*PassanggerId* tipe Integer
*Suverved* Tipe Integer
*Pclass* Tipe Integer
*Name* Tipe Faktor
*Sex* Tipe Faktor
*Age* Tipe Numerik
*Sibsp* Tipe Integer
*Parch* Tipe Integer
*Ticket* Tipe Faktor
*Fare* Tipe Numerik
*Cabin* Tipe Faktor
*Embarked* Tipe Faktor

Kita dapat mengetahui tipe-tipe data masing-masing variabel dan nama-nama variabel dalam dataset.

### Mengecek Missing Data

```{r}
sapply(df, function(x) sum(is.na(x)))

```
Terdapat 145 NaN pada feature Age


```{r}
vis_miss(df)
```
Dapat dilihat dari plot yang disediakan bahwa distribusi NaN value terletak banyak di feature Age


### Mengecek Outlier

Outlier adalah data yang berbeda dengan data lainnya. Nilai ini kadang menjadi nilai yang penting untuk diamati, namun kadang juga menjadi gangguan pada penerapan metode Machine Learning. Pada modul ini, nantinya nilai ini akan dihapus dengan pertimbangan tertentu. Kemudian, untuk melihat apakah ada outlier atau tidak dalam suatu dataset dapat dilihat melalui boxplot berikut:
```{r}
num_cols <- unlist(lapply(df, is.numeric)) #Memilih kolom bertipe numerik
df_num <- df[ , num_cols]  
boxplot(df_num)
```

### Melihat Korelasi Data
```{r}
plot_correlation(df_num)

```
Korelasi tertinggi terdapat pada Feature Parch dan SibSp
Perlu dicatat bahwa, missing data membuat hasil plot di atas kurang maksimal. Namun demikian, pada notebook ini kita fokus pada EDA dan Pemodelan SVM jadi kita biarkan dulu. Nanti baru dihapus.

### Melihat Statistik Data
```{r}

summary(df)

```
Melihat Info dari Feature yang ada 

### Plot Distribusi Data Numerik
```{r}

d <- melt(df_num)
ggplot(d,aes(x = value)) + 
    facet_wrap(~variable,scales = "free_x") + geom_histogram()
```

Plot ini untuk melihat apakah variabel-variabel pada dataset berdistribusi normal. Variabel-variabel Age, SibSp, Parch, dan Fare cenderung memiliki skewnes positif. Itu berarti berarti ekor distribusi berada di sebelah kanan nilai terbanyak.

### Pairplot
```{r}
pairs.panels(df_num, 
             method = "pearson", # correlation method
             hist.col = "#00AFBB",
             density = TRUE,  # show density plots
             ellipses = TRUE # show correlation ellipses
             )
```
Melihat distribusi yang ada dengan korelasi feature survived

## Data Pre Processing
Data preprocessing ini digunakan guna menyiapkan data untuk diklasifikasi menggunakan metode SVM(Hanya Contoh).

Setelah mengetahui hasil EDA di atas maka untuk hasil yang baik diperlukan beberapa hal sebagai berikut:
1. Menghapus kolom teks yang tidak diperlukan: **Name** dan **Ticket**
2. Mengisi NaN pada kolom **Cabin** dengan salah satu nama kabin tertentu*, mengisi NaN pada kolom **Age **dengan nilai rata-ratanya
3. Melakukan pengkodean(Encoding) pada kolom **Sex** , **Cabin**, dan **Embarked**
4. Menghapus outlier
5. Karena nilai data ada yang sangat besar dan kecil maka perlu dilakukan normalisasi

Setelah data diperbaiki dilakukan langkah sebagai berikut:
1. Memilih variabel independent dan label
2. Membagi data menjadi data training dan data testing


[Note] * Ini hanya contoh untuk melakukan pengisian data NaN(Kosong), nama kabin mungkin menjadi penting sehingga tidak segampang itu diganti

### Seleksi Kolom

```{r}
df = subset(df, select = -c(Name, Ticket) )
head(df)

```

### Mengisis NaN
```{r}

#Mengisi NA pada kolom Age dengan mean(Age)
df$Age[is.na(df$Age)] = 0
m<-mean(df$Age)
df$Age[df$Age==0]<-m

#Mengisi NA pada kolom Cabin dengan E49
df=df %>% replace_na(list(Cabin = "E49"))

#Mengisi NA pada kolom Embarked dengan C
df=df %>% replace_na(list(Embarked = "C"))

#Mengecek apakah NA sudah terganti
sapply(df, function(x) sum(is.na(x)))
```


```{r}
head(df)
```


### Melakukan Pengkodean(Encoding)
```{r}
df$Sex<- unclass(df$Sex)
df$Embarked<- unclass(df$Embarked)
df$Cabin<- unclass(df$Cabin)
head(df)
```


### Menghapus Outlier
```{r}
#' Detect outliers using IQR method
#' 
#' @param x A numeric vector
#' @param na.rm Whether to exclude NAs when computing quantiles
#' 
is_outlier <- function(x, na.rm = FALSE) {
  qs = quantile(x, probs = c(0.25, 0.75), na.rm = na.rm)

  lowerq <- qs[1]
  upperq <- qs[2]
  iqr = upperq - lowerq 

  extreme.threshold.upper = (iqr * 3) + upperq
  extreme.threshold.lower = lowerq - (iqr * 3)

  # Return logical vector
  x > extreme.threshold.upper | x < extreme.threshold.lower
}

#' Remove rows with outliers in given columns
#' 
#' Any row with at least 1 outlier will be removed
#' 
#' @param df A data.frame
#' @param cols Names of the columns of interest. Defaults to all columns.
#' 
#' 
remove_outliers <- function(df, cols = names(df)) {
  for (col in cols) {
    cat("Removing outliers in column: ", col, " \n")
    df <- df[!is_outlier(df[[col]]),]
  }
  df
}


vars_of_interest <- c("Age", "SibSp", "Parch", "Fare")


df_filtered <- remove_outliers(df, vars_of_interest)

```

```{}
boxplot(df_filtered)
```

### Normalisasi Data

Karena tujuannya adalah klasifikasi menggunakan SVM maka normalisasi data wajib dilakukan.

```{r}
unit_length <- function(x) {
                            x / sqrt(sum(x^2))
                            }
unit_length_df <- as.data.frame(lapply(df, unit_length))

head(unit_length_df)
```

### Memilih Variable Target & Variabel Independent

```{r}
y=df$Survived
x=data.matrix(df[-c(2)])
```
### Membagi Data Menjadi Data Training dan Data Testing
```{r}
require(caTools)  # loading caTools library

set.seed(123)   #  set seed to ensure you always have same random numbers generated
sample = sample.split(df,SplitRatio = 0.75) # splits the data in the ratio mentioned in SplitRatio. After splitting marks these rows as logical TRUE and the the remaining are marked as logical FALSE
train1 =subset(df,sample ==TRUE) # creates a training dataset named train1 with rows which are marked as TRUE
test1=subset(df, sample==FALSE)

```

**This is the end of Notebooks**
say: Allhamdulillah, panjang banget dah

